{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TSMH.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN8clLX4JSUAioxTI8elpC9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install transformers"],"metadata":{"id":"55RHeaE4OXGO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647780903807,"user_tz":-330,"elapsed":9885,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"7042bac6-2af8-400e-c7c4-fef16e43ce52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 62.4 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U28akBCq7YGv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647780927980,"user_tz":-330,"elapsed":16982,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"0b31351d-d883-4688-8a2d-cb59bacc68c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/DATA\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/DATA\")"]},{"cell_type":"code","source":["import torch\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from torchtext.legacy.data import Field, LabelField, BucketIterator, TabularDataset\n","\n","import spacy\n","import numpy as np\n","import pandas as pd\n","\n","import random\n","import math\n","import time\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"ev5v5fChR-7e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Yelp Dataset"],"metadata":{"id":"uAUFAfYjfC5r"}},{"cell_type":"code","source":["# with open(\"/content/1000.pos\",'r') as f:\n","#   p_data = f.read().split('\\n')\n","#   # print(data)\n","\n","# with open(\"/content/1000.neg\",'r') as f:\n","#   n_data = f.read().split('\\n')"],"metadata":{"id":"vb_fk7DrqdYs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Amazon dataset"],"metadata":{"id":"UqwLxsRmfFVK"}},{"cell_type":"code","source":["p_data = pd.read_csv(\"/content/amazon_pos_data.csv\")['review'].tolist()\n","n_data = pd.read_csv(\"/content/amazon_neg_data.csv\")['review'].tolist()"],"metadata":{"id":"bs-ffohHUTVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open(\"/content/tsmh_pos.txt\",'r') as f:\n","#   p_test_data = f.read().split('\\n')[:-1]\n","#   # print(data)\n","\n","# with open(\"/content/tsmh_neg.txt\",'r') as f:\n","#   n_test_data = f.read().split('\\n')[:-1]\n","\n","\n","# for i,review in enumerate(p_test_data):\n","#   p_test_data[i] = review[1:-3].strip()\n","\n","\n","# for i,review in enumerate(n_test_data):\n","#   n_test_data[i] = review[1:-3].strip()"],"metadata":{"id":"b1rzlwzH1bOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_data[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NRvTGIoZ9Lm2","executionInfo":{"status":"ok","timestamp":1647780944111,"user_tz":-330,"elapsed":23,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"42e378be-2e7d-4c33-af85-d9eb30570702"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'evening clutch bag'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["Positive_train = list(set(p_data[:10000]))\n","# Positive_val = list(set(Positive[-1000:]['review']))\n","Positive_test = list(set(p_data[14000:]))\n","\n","Negative_train = list(set(n_data[:10000]))\n","# Negative_val = list(set(Negative[-1000:]['review']))\n","Negative_test = list(set(n_data[14000:]))\n","len(Positive_train) ,len(Negative_train) , len(Positive_test), len(Negative_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYrB15v9qfw2","executionInfo":{"status":"ok","timestamp":1647780944113,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"89d26319-9145-4521-f957-ba66216b1851"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9073, 8942, 968, 959)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["spacy_en = spacy.load('en_core_web_sm')\n","\n","def tokenizer(text):\n","  return text.split()\n","  # return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","\n","def add_tokens(x):\n","  x = [tok.text for tok in spacy_en.tokenizer(x)]\n","  while len(x) < 5:\n","    x = x + ['<pad>']\n","\n","  return \" \".join(x)"],"metadata":{"id":"TcYUsk3Lqjcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Train = pd.DataFrame({\"review\": Positive_train + Negative_train, \"label\": [1]*len(Positive_train) + [0]*len(Negative_train)})\n","# Val = pd.DataFrame({\"review\": Positive_val + Negative_val, \"label\": [1]*len(Positive_val) + [0]*len(Negative_val)})\n","Train = Train.sample(frac = 1)\n","Test = pd.DataFrame({\"review\": Positive_test + Negative_test, \"label\": [1]*len(Positive_test) + [0]*len(Negative_test)})\n","# Test = Test.sample(frac = 1)\n","\n","Train['review'] = Train['review'].apply(add_tokens)\n","# Val['review'] = Val['review'].apply(add_tokens)\n","Test['review'] = Test['review'].apply(add_tokens)\n","\n","Train.to_csv('/content/train.csv',index=False)\n","# Val.to_csv('/content/val.csv',index=False)\n","Test.to_csv('/content/test.csv',index=False)\n","Test.tail(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"rqxQ5q7fquZv","executionInfo":{"status":"ok","timestamp":1647780953256,"user_tz":-330,"elapsed":1904,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"a2c0c071-433d-40bf-c95d-06cd41dfce0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               review  label\n","1922  ripoff , like the rest of the stones remastered      0\n","1923                     not as good as high fidelity      0\n","1924                       boring ! boring ! boring !      0\n","1925    should have listened to the other reviews ...      0\n","1926                    disappointing ! ! <pad> <pad>      0"],"text/html":["\n","  <div id=\"df-cc8aab99-8bb1-4c1f-bcc5-8b54da2e79e4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1922</th>\n","      <td>ripoff , like the rest of the stones remastered</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1923</th>\n","      <td>not as good as high fidelity</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1924</th>\n","      <td>boring ! boring ! boring !</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1925</th>\n","      <td>should have listened to the other reviews ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1926</th>\n","      <td>disappointing ! ! &lt;pad&gt; &lt;pad&gt;</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc8aab99-8bb1-4c1f-bcc5-8b54da2e79e4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc8aab99-8bb1-4c1f-bcc5-8b54da2e79e4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc8aab99-8bb1-4c1f-bcc5-8b54da2e79e4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["REVIEW = Field(sequential=True,\n","               tokenize = tokenizer,\n","               use_vocab = True, \n","               # init_token = '<sos>', \n","               # eos_token = '<eos>', \n","               lower = True,\n","               batch_first = True)\n","\n","LABEL = LabelField(dtype=torch.long, \n","                   batch_first=True, \n","                   sequential=False)\n","\n","fields = [('review', REVIEW), ('label',LABEL)] # ('token_type', TTYPE), ('start',START), ('end',END)]"],"metadata":{"id":"zTlzM0VlqucC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data, val_data, test_data = TabularDataset.splits(\n","                                        path = '/content/',\n","                                        train = 'train.csv',\n","                                        validation = 'test.csv',\n","                                        test = 'test.csv',\n","                                        format = 'csv',\n","                                        fields = fields,\n","                                        skip_header = True)\n","print(type(train_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E91p63QsqueS","executionInfo":{"status":"ok","timestamp":1647780963843,"user_tz":-330,"elapsed":455,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"46869fb1-a00f-43ec-b582-29e8598df9e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torchtext.legacy.data.dataset.TabularDataset'>\n"]}]},{"cell_type":"code","source":["REVIEW.build_vocab(train_data,val_data, min_freq = 1) # train_data must be of type <class 'torchtext.legacy.data.dataset.TabularDataset'>\n","LABEL.build_vocab(train_data, test_data)\n","print(len(REVIEW.vocab),len(LABEL.vocab))\n","print(REVIEW.vocab.stoi['<eos>'] , REVIEW.vocab.stoi['<sos>'], REVIEW.vocab.stoi['<pad>'])\n","print(train_data[0].__dict__.keys())\n","print(train_data[20].__dict__.values())\n","print(list(REVIEW.vocab.stoi.items())[:10])\n","\n","\n","BATCH_SIZE = 10\n","\n","train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n","                                                      (train_data, val_data, test_data), \n","                                                      batch_size = BATCH_SIZE,\n","                                                      sort_key = lambda x : len(x.review),\n","                                                      shuffle = False,\n","                                                      device = device\n","                                                    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bb6EBKJQquhH","executionInfo":{"status":"ok","timestamp":1647780966592,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"491b194e-fa68-4ba0-d27f-369b3a5c1748"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12745 2\n","0 0 1\n","dict_keys(['review', 'label'])\n","dict_values([['fun', 'film', '<pad>', '<pad>', '<pad>'], '1'])\n","[('<unk>', 0), ('<pad>', 1), ('!', 2), ('the', 3), ('a', 4), (',', 5), ('.', 6), ('of', 7), ('not', 8), ('this', 9)]\n"]}]},{"cell_type":"code","source":["for batch in test_iterator:\n","  print(batch.review)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sg8UgtRQ3220","executionInfo":{"status":"ok","timestamp":1647780980248,"user_tz":-330,"elapsed":409,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"72c36419-ed2a-4909-d650-cf9aa207ff17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 5776,  1814,    10,  1175,    20],\n","        [ 1593,  1137,    35,  2203,   944],\n","        [ 1424,   238,  1158,  6968,     6],\n","        [ 5783,   120,   630,     1,     1],\n","        [   18,     7,  2697,  2032,     1],\n","        [ 1376,     3,   262,     1,     1],\n","        [ 2897,  1998, 12077,     1,     1],\n","        [  142,   289,     1,     1,     1],\n","        [  189,    19,     1,     1,     1],\n","        [  170,     1,     1,     1,     1]])\n"]}]},{"cell_type":"code","source":["from torch import nn\n","import torch.nn.functional as F\n","\n","class TextClassificationModel(nn.Module):\n","\n","  def __init__(self, vocab_size, embed_dim, num_filters, num_class):\n","    super(TextClassificationModel, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=False)\n","    self.fc = nn.Linear(num_filters, num_class)\n","    self.dropout = nn.Dropout(0.25)\n","    self.conv2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size = (2,embed_dim), stride = 1, padding = 0, padding_mode='zeros', dilation=1, bias = True)\n","    self.conv3 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size = (3,embed_dim), stride = 1, padding = 0, padding_mode='zeros', dilation=1, bias = True)\n","    self.conv4 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size = (4,embed_dim), stride=1, padding = 0, padding_mode= 'zeros', dilation=1, bias = True)\n","    self.conv5 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size = (5,embed_dim), stride=1, padding = 0, padding_mode = 'zeros', dilation=1, bias = True)\n","\n","    self.init_weights()\n","\n","\n","  def init_weights(self):\n","    initrange = 0.5\n","    self.embedding.weight.data.uniform_(-initrange, initrange)\n","    self.fc.weight.data.uniform_(-initrange, initrange)\n","    self.conv3.weight.data.uniform_(-initrange, initrange)\n","    self.conv4.weight.data.uniform_(-initrange, initrange)\n","    self.conv5.weight.data.uniform_(-initrange, initrange)\n","    self.fc.bias.data.zero_()\n","\n","  def forward(self, X):\n","\n","    # X, Y = [batch size, seq len] , [batch size]\n","\n","    embedded = self.dropout(self.embedding(X))\n","\n","    # embedded = [batch size, seq len, emb dim]\n","\n","    embedded = embedded.unsqueeze(1)\n","\n","    # embedded = [batch size, channel , seq len, emb dim]\n","    e2 = self.conv2(embedded)\n","    e3 = self.conv3(embedded) # [ batch size, channel , seq len - 3 + 1, 1]\n","    e4 = self.conv4(embedded) # [ batch size, channel , seq len - 4 + 1, 1]\n","    e5 = self.conv5(embedded) # [ batch size, channel , seq len - 5 + 1, 1]\n","\n","    e2 = F.max_pool2d(e2, kernel_size=(e2.shape[-2],1)).squeeze(1).squeeze(-1)  # [batch size, 1]\n","    e3 = F.max_pool2d(e3, kernel_size=(e3.shape[-2],1)).squeeze(1).squeeze(-1)  # [batch size, 1]\n","    e4 = F.max_pool2d(e4, kernel_size=(e4.shape[-2],1)).squeeze(1).squeeze(-1)   # [batch size , 1 ]\n","    e5 = F.max_pool2d(e5, kernel_size=(e5.shape[-2],1)).squeeze(1).squeeze(-1)    # [batch size , 1 ]\n","\n","    return self.fc(torch.concat((e2,e3,e4,e5),dim=-1))\n","\n","sentiment_model = TextClassificationModel(len(REVIEW.vocab), 300, 4, 2).to(device)\n","# sentiment_model.embedding.weight.data.copy_(REVIEW.vocab.vectors)\n","sentiment_model.embedding.weight.requires_grad = True\n","# model.embedding.weight\n","\n","optimizer = optim.Adam(sentiment_model.parameters(), lr = 0.01)\n","criterion = nn.CrossEntropyLoss().to(device)"],"metadata":{"id":"TYhRx_n-pr2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_model.load_state_dict(torch.load(\"/content/DATA/MyDrive/LAB_work/TSMH/amazon_classification_yoon_kim_model.pt\",map_location=device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwEeYDL9rCTu","executionInfo":{"status":"ok","timestamp":1647781099496,"user_tz":-330,"elapsed":1048,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"6cee5f08-44c9-4ed3-871d-6e458c1bc84f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["test_acc = 0\n","sentiment_model.eval()\n","with torch.no_grad():\n","\n","  for batch in test_iterator:\n","\n","      X = batch.review.to(device)\n","      # print(X.size())\n","      Y = batch.label.to(device)\n","\n","      y_pred = sentiment_model(X)\n","      \n","      # for i,x in enumerate(X):\n","        # for tokens in x.numpy().tolist():\n","        #   print(REVIEW.vocab.itos[tokens],end=' ')\n","        # print()\n","        # print(y_pred[i])\n","        \n","      test_acc += (y_pred.argmax(dim=-1) == Y).sum().item()\n","\n","print(f\"Test Acc : {test_acc/(2000):.4f}\")"],"metadata":{"id":"qD7LiuwNsjik","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647803202303,"user_tz":-330,"elapsed":539,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"ab92c46f-82df-4fea-fcaa-84f675b729b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Acc : 0.7625\n"]}]},{"cell_type":"markdown","source":["TSMH algorithm for generating text"],"metadata":{"id":"HzGIzVRECi7p"}},{"cell_type":"code","source":["U = dict()\n","# U[\"[QWH]\"] = [\"what\", \"when\", \"where\", \"which\", \"who\", \"whom\", \"whose\", \"why\", \"how\"]\n","# AUX = []\n","# U[\"[NEG]\"] = ['not','none','never','no','no one',\"negative\", 'neither','bad', 'horrible','unworthy','nuisance', 'horrifying experience','stupid choice', 'illegal activities','illogical' ,'horrendous', \"unexpected\" ,\"is not\",\"would not\",\"false\",\"nuisance\",\"nasty\",'depressing','disgusting','do not','against','disapprove','disgrace','aweful','unpleasant','troublesome','abhor','abominable','angry','annoy', 'annoying experience', 'beware', 'boring','brutal','misfortune','catastrophic decision','waste of resources'] # ,'disappointment','disappointing','disappoint','destructive','destruction','meangingless','gruesome']\n","U[\"[POS]\"] = ['nice','wow','amazing','approve','yes',\"positive\", 'either','amused', 'smooth','totally worthy of','good', 'even better','not at all stupid choice', 'perfect',\"clean\",\"superb\",'recommend','graceful attitude','pleasant','peaceful',\"awesome\",\"how nice\",\"superb\",'graceful','jubiliant','exquisite','dazzling','bliss','favourable','marvellous','lucid','intellectual choice','novel','robust','thriving','virtuous','amicable','appreciate','brilliant','cajole','bravo','really brave','captivating','charming','colourful','coolest item ever !','commendable'] # ,'disappointment','disappointing','disappoint','destructive','destruction','meangingless','gruesome']\n","\n","U[\"[NN]\"] = []\n","# U[\"[NNP]\"] = []\n","\n","with open(\"/content/DATA/MyDrive/LAB_work/TSMH/verbs.txt\",'r') as f:\n","  temp = f.read().split('\\n')\n","  U[\"[AUX]\"] = [x for x in temp if x not in \"[POS]\"]\n","\n","# print(len(AUX))  # 4576\n","vocab_partition = [\"[AUX]\", \"[POS]\", \"[OTH]\"]\n","U.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYSeF4MnMXwq","executionInfo":{"status":"ok","timestamp":1647803202931,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"918e24e3-091b-4965-9a9d-39f6d39ef86f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['[POS]', '[NN]', '[AUX]'])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["Data = []\n","\n","# with open('/content/1000.pos','r') as f:\n","#   temp = f.read().split('\\n')\n","#   Data = [x for x in temp]\n","\n","# print(len(Data)) # 1001\n","\n","Data = pd.read_csv(\"/content/amazon_pos_data.csv\")['review'].tolist()\n","# Data = [x for x in temp]\n","\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot([len(x.split()) for x in Data])\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"XFvbfG8UNXmi","executionInfo":{"status":"ok","timestamp":1647803205309,"user_tz":-330,"elapsed":888,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"0bdfa956-a2f6-4b85-e9f6-672ce9fbecec"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","\n","ex = \"disappointing experience from the cake factory!!\"\n","def Name_entity_recognition(sent):\n","    sent = word_tokenize(sent)\n","    sent = pos_tag(sent)\n","    return sent\n","\n","for d in Data:\n","  sent = Name_entity_recognition(d)\n","  for s in sent:\n","    if s[-1] == \"NNS\" or s[-1] == \"NN\":\n","      U['[NN]'].append(s[0])\n","\n","for ele in set(U['[AUX]']).intersection(set(U['[NN]'])):\n","  U['[AUX]'].remove(ele)\n","\n","\n","for ele in set(U['[AUX]']).intersection(set(U['[POS]'])):\n","  U['[AUX]'].remove(ele)\n","\n","\n","U['[AUX]'] = list(set(U['[AUX]']))\n","# U['[POS]'] = list(set(U['[POS]']))\n","U['[NN]'] = list(set(U['[NN]']))\n","U['[POS]'] = list(set(U['[POS]']))\n","# U['[QWH]'] = list(set(U['[QWH]']))\n","# U['[AUX]'] = set(U['[AUX]'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoy2IRbIcUZ5","executionInfo":{"status":"ok","timestamp":1647803212699,"user_tz":-330,"elapsed":7401,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"13b25342-985c-4632-ce1f-c0a71c0d1ccc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"code","source":["U.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enFd9FGXxVZm","executionInfo":{"status":"ok","timestamp":1647803212699,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"aba50770-307f-4502-e016-ecb4463721f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['[POS]', '[NN]', '[AUX]'])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import BertTokenizer, BertForMaskedLM\n","\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","bert_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n","\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOqE164H7e3a","executionInfo":{"status":"ok","timestamp":1647803229349,"user_tz":-330,"elapsed":16655,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"1a3826aa-af24-49f9-8023-08f467e9390b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["def BERT_Sentence_generator(sent):\n","\n","  # tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","  # bert_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n","  bert_output = []\n","\n","  # sample 1 sentence from one the of constraint satisfaction class\n","  # sent = random.sample(list(temporary_set),1)\n","\n","  bert_model.eval()\n","  inputs = bert_tokenizer.encode(sent[0], return_tensors=\"pt\")\n","  labels = bert_tokenizer.encode(sent[0], return_tensors=\"pt\")\n","\n","  outputs = bert_model(inputs, labels=labels)\n","  loss = outputs.loss\n","  logits = outputs.logits\n","  bert_output.append(bert_tokenizer.decode(logits.argmax(dim=-1)[0].detach().cpu().numpy()))\n","\n","  return bert_output\n","\n","# ********************************************#\n","\n","\n","def GPT2_Scorer(sentence):\n","\n","  # tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","  # gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","  inputs = gpt2_tokenizer(sentence, return_tensors=\"pt\")  # sentence = \"Hello, my dog is cute\"\n","  outputs = gpt2_model(**inputs, labels=inputs[\"input_ids\"])\n","  loss = outputs.loss\n","  # logits = outputs.logits\n","\n","  return np.exp(-loss.detach().cpu()*inputs[\"input_ids\"].shape[-1])\n","\n","\n","# ********************************************#\n","\n","\n","def Sentiment_Scorer(bert_output):\n","  sentiment_model.eval()\n","\n","  bert_output = add_tokens(bert_output)\n","\n","  # assert len(bert_output.split()) >= 5, \"Sentiment analysis model would fail !!\"\n"," \n","  with torch.no_grad():\n","    X = torch.tensor([REVIEW.vocab.stoi[token] for token in bert_output.split()]).unsqueeze(0).to(device)\n","    try:\n","      Y = sentiment_model(X).squeeze(0)\n","    except :\n","      return 0\n","\n","    Y = Y.detach().cpu()\n","    sentiment_score = F.log_softmax(Y).numpy()[0]\n","  \n","  return np.exp(sentiment_score)\n"],"metadata":{"id":"rM-HwSu1g6zk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import copy\n","\n","constraint_count_set = dict()\n","operations = [\"insert\", \"replace\", \"delete\", \"none\"]\n","vocab_partition = [\"[AUX]\",\"[POS]\",\"[NN]\",\"[OTH]\"]\n","\n","#***************************************#\n","def Count_constraints(sentence):\n","\n","  global vocab_partition\n","\n","  temp = dict()\n","\n","  for i in vocab_partition:\n","    temp[i] = 0\n","\n","  cnt = 0\n","\n","  # print(f\"Inside Count_constraint function: {sentence}, {len(vocab_partition)}\")\n","\n","  for word in sentence.split():\n","    for _ in vocab_partition:\n","      temp[_]  += int((_ in U.keys() and word in U[_]) or (_ == word))\n","\n","  for _ in vocab_partition:\n","    cnt += int((_ == '[POS]' and temp[_]>= 1) or  (_ != '[POS]' and temp[_]>0))\n","\n","  return len(vocab_partition) - cnt\n","\n","\n","# **************************************#\n","\n","def dfs(sampled_indices,ner_list,sent,idx=0):\n","\n","  # print(sampled_indices)\n","  if len(sampled_indices) == 0:\n","    # print(\"Got into 0\")\n","    constraint_count_set[Count_constraints(sent)].append(sent)\n","    return \n","  \n","  if idx == sampled_indices[0]:\n","    # print(\"Got into\")\n","    sampled_indices = sampled_indices[1:]\n","    \n","    for operation in operations:\n","      sentence = copy.deepcopy(sent)\n","      if operation == 'none':\n","        sentence += ' ' + ner_list[idx][0] # (\"string\", \"NER tag\")\n","        dfs(sampled_indices,ner_list,sentence,idx+1)\n","      if operation == 'delete':\n","        dfs(sampled_indices,ner_list,sentence,idx+1)\n","      if operation == 'insert' or operation == 'replace':\n","        for vocab in vocab_partition:\n","          # if vocab != '[OTH]':\n","          sentence += ' ' + vocab\n","          dfs(sampled_indices,ner_list,sentence,idx+1)\n","      # if operation == 'replace':\n","        # for vocab in vocab_partition:\n","        #   if vocab in U.keys():\n","        #     sentence += ' ' + vocab\n","        #     dfs(sampled_indices,ner_list,sentence,idx+1)\n","  else:\n","    sent += ' ' + ner_list[idx][0]\n","    dfs(sampled_indices,ner_list,sent,idx+1)\n","\n","\n","\n","# **************************************#\n","\n","\n"],"metadata":{"id":"-vPlapjQg2tP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import queue\n","import threading\n","from threading import Thread"],"metadata":{"id":"-tNBwSb7ojn9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_pos_sent = []"],"metadata":{"id":"IM105cpt94lH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for data in Data[250:]:\n","  chosen_sentence = data\n","  print(f\"Input Sentence: {chosen_sentence}\")\n","\n","  constraint_count_set = dict()\n","  operations = [\"insert\", \"replace\", \"delete\", \"none\"]\n","  vocab_partition = [\"[AUX]\",\"[POS]\",\"[NN]\",\"[OTH]\"]\n","\n","  k = 4   # number of positions to sample from the input sentence\n","\n","\n","  # 5 MCMC steps\n","  for iter in range(5):\n","\n","    # print(f\"#*********************# Step : {iter+1} #*********************#\")\n","\n","    # randomly choose k positions\n","    ner_list = Name_entity_recognition(chosen_sentence)\n","    # print(ner_list)\n","\n","    # vocab_partition.append()\n","    # print(vocab_partition)\n","\n","    #sample indices to carry out combination of operations\n","    sampled_indices = sorted(random.sample(list(range(len(ner_list))),min(k,len(ner_list))))\n","\n","    # initialise the a map: int --> list, # num constraints satisfied --> the list of sentences doing so\n","    for i in range(10):\n","      constraint_count_set[i] = []\n","\n","    # ner_list_copy = copy.deepcopy(ner_list)\n","\n","    dfs(sampled_indices,ner_list,\"\",0)\n","\n","    # for k,v in constraint_count_set.items():\n","    #   print(len(v))\n","\n","    temporary_set = set()\n","    for _,v in constraint_count_set.items():\n","      if len(v) > 0:\n","        for sentence in v:\n","          temp = sentence.split()\n","          for idx,token in enumerate(temp):\n","            if token == '[POS]':  # replace the Negative tokens by sampling from the [POS] subset\n","              temp[idx] = random.sample(U[\"[POS]\"],1)[0]\n","            elif token == '[NN]':   # replace the Noun tokens by sampling from the [NN] subset\n","              temp[idx] = random.sample(U[\"[NN]\"],1)[0]\n","            elif token[0] == '[':  # rest of the tokens to be replaced by words generated from BERT\n","              temp[idx] = '[MASK]'\n","              \n","          temporary_set.add(' '.join(temp))\n","        break  # acting only on the set of max constraint satisfaction\n","\n","    # print(temporary_set)\n","    # print(f\"{len(temporary_set)} sentences generated !\")\n","\n","    que = queue.Queue()\n","\n","    threads_list = list()\n","    \n","    sentence = random.sample(list(temporary_set),1)\n","    bert_output = BERT_Sentence_generator(sentence)\n","    # PI = GPT2_Scorer(bert_output[0][1:-1])\n","    # sentiment_score = Sentiment_Scorer(bert_output[0][1:-1])\n","\n","    t1 = threading.Thread(target=lambda q, arg1: q.put(GPT2_Scorer(arg1)), args=(que, bert_output[0][1:-1]))\n","    t2 = threading.Thread(target=lambda q, arg1: q.put(Sentiment_Scorer(arg1)), args=(que, bert_output[0][1:-1]))  \n","    # starting threads\n","    t1.start()\n","    t2.start()\n","    threads_list.append(t1)\n","    threads_list.append(t2)\n","\n","\n","    t3 = threading.Thread(target=lambda q, arg1: q.put(GPT2_Scorer(arg1)), args=(que, chosen_sentence))\n","    t4 = threading.Thread(target= lambda q, args1: q.put(Sentiment_Scorer(args1)), args=(que, chosen_sentence))\n","\n","    # starting threads\n","    t3.start()\n","    t4.start()\n","\n","\n","    threads_list.append(t3)\n","    threads_list.append(t4)\n","\n","    # Join all the threads\n","    for t in threads_list:\n","        t.join()\n","\n","    # Check thread's return value\n","    result = []\n","    while not que.empty():\n","      result.append(que.get())\n","\n","    '''result = []\n","    result.append(GPT2_Scorer(bert_output[0][1:-1]))\n","    result.append(Sentiment_Scorer(bert_output[0][1:-1]))\n","\n","    result.append(GPT2_Scorer(chosen_sentence))\n","    result.append(Sentiment_Scorer(chosen_sentence))'''\n","\n","    assert len(result) == 4, f\"Only {len(result)} threads have merged out of {4} !!\"\n","\n","    Acceptance_rate = min(1,(result[0]*result[1])/(result[2]*result[3]))\n","\n","    if Acceptance_rate == 1:\n","      chosen_sentence = bert_output[0][1:-1]\n","\n","  print(f\"Output sentence : {chosen_sentence[1:-1]}\")\n","  new_pos_sent.append(chosen_sentence[1:-1])\n","  print('*' * 50)\n"],"metadata":{"id":"KtWavMgsSEsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(new_pos_sent))"],"metadata":{"id":"BxkxNEzRBB9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647812977111,"user_tz":-330,"elapsed":392,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"f9664e16-29f4-41d0-9363-9f1c8c707dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["58\n"]}]},{"cell_type":"code","source":["for _ in new_pos_sent:\n","  print('\"',_,'\"',',')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_KhaNNI-ldg","executionInfo":{"status":"ok","timestamp":1647812977977,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"86992cd2-9ab4-4c2a-a8c4-109689b07d8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\" he's a really brave and peaceful end.. luc i appreciate building and capting my dads'friend, and how a pleasant. hes, of course like floor \" ,\n","\" an extremely peaceful bracelet, that i would recommend money instead of, yes glassware not at all stupid and brilliant, a positive zone that amused giordano to bequentle \" ,\n","\" and an arm of even better contech technology, a very more luc \" ,\n","\" the jubilientt and dazzling carpenters were the marvel of a captivating fav \" ,\n","\" oh, good to graceful and wow guerou. good to the awesomeness. a little com. good to \" ,\n","\" best novel ( ), ae125 ( michael crlanton ) exquisitely pleasant microwave ( favourable service, cool best item ever ) best attitude ) : h'allo! grandmas ( oh how nice ) nice database \" ,\n","\" how much more bertful mathematics in hick and and is not at all stupid so much positive infrequentness ` ` dijoy a really brave placebo \" ,\n","\" not totally worthy of wayne ander, but even better annabel. even more superb and not at all stupid choice \" ,\n","\" a, sinful, brilliant choice, charming germanofonly, bravo, lucid in concert, a brilliant \" ,\n","\" a, more,. the most smoothest, perfect auto,, pure, the coolest, perfect and perfect perfect pitch \" ,\n","\" very good to to, briefcase, gorgeous, colourful, totally worthy of all ), highschool girls, very highly commen \" ,\n","\" : not at all stupid. pm! : best item ever!. of course charming. a graceful attitude - from excellant to a top! : dazzling \" ,\n","\" an oft, begginn, starmending karloff or yello, an wonderfully graceful attitude and a... a all of multitudes, superbly virt in in their perfect thanks - and in sizes. \" ,\n","\" an add - in, better, and totally worthy of bebiliant inspectors. luc and ellen. i appreciate must - buy \" ,\n","\" the marvel of the perfect is even to appreciated. how nice babylon of the nightmares not at all how very marvel \" ,\n","\" a unique and graceful kodak. not at all a really brave platonic choice ok? a virtuous master a. are nice. fiction of of intellectual choice. a very charming. of a really brave dreamcoat b. bravo larry. amicable best \" ,\n","\" a novel of not at all stupid choice cane, and perhaps not at all stupid and not at all stupid choice daigrepont, how nice peeler, and how a and a \" ,\n","\" a lot of people., a, not approve. in fact approve blue, either... - uh,, uh and not at all an of choice \" ,\n","\" great, and either way not at all stupid choice hummingbird ~ / / [ thriving ] a good place, nice and able leeway / / stupid choice / / / the thriving \" ,\n","\" a marvel of of novel. beauty of her graceful attitude the virting shawnee woman the anivating gong \" ,\n","\" her first name is \" bravo mammals, bravo fliky, \" ,\n","\" forget, not at all stupid choice little smart cutie say yes sweat say yes properly. even better reiview is the marvel of kensington. \" ,\n","\" ` `, with their amazing heyday devotions, and i appreciate the perfect combination of calm and all - snimights, and robust espresso - manhattans - \" ,\n","\" bravo bravo bolt. not all brilliant energy. all pleasant meooooooooww. the coolest item ever! title choice. awesome dazzling brilliant dazzling chango brilliant light novel end.. \" ,\n","\" - a very brave tea party, i recommend bernnels in either garden or, yes, peaceful, \" ,\n","\" the, pleasent - not at all stupid choice award winner winner of the \" exquisite ignition \" award : the brilliant kitchen 2kp26m1xnp - liza b \" ,\n","\" the average, good biscuits. who would like king to be a not at all stupid a chance of a hrm and a \" ,\n","\" a pleasant stop, most likely even better and pleasant be, the sort of excellent and the coolest item ever! retreat and banquet with ami quick, yes akjee not so \" ,\n","\" the - id, the - wow, ri - a -jole buggy, positive fill line, and positive duty, the bliss konnie \" ,\n","\" [ unk ] a brilliant school of instructions. -ly of momofallo shod ( ) clean vacations and colourful days \" ,\n","\" the thriving cheap / semi - decent of the the exquisite ano ' \" ,\n","\" a, a, either, or. a graceful lagreen girl, a captivating nutcracker, amazing powerhouse, great player, in choice, really brave \" ,\n","\" more favourable at the exquisite beasts. stupid choice to see round here. better raisins a'clean. a few luc \" ,\n","\" school inspector approves of beautiful battery, and beautiful family homes recommended multi - classrooms \" ,\n","\" the how nice it is.. clean.. how positive. even better.. how. is it or burning \" ,\n","\" a pleasant and, clean and thriving, clean drinks - marker in a pleasant science of grass. wow leo, exquisitely smooth pf \" ,\n","\" the positive and pleasant and exquisite of a smooth adam, an exquisite thought \" ,\n","\" i am brilliant motivator with exquisite burner, exquisite most dazzling entry and most brilliant lawn and best item ever! an amicable widg \" ,\n","\" ` ` ` george wallace would approve that, nuttiest ` `'ringo starr, a colourful pill - ami friendly and \" ,\n","\" the words changed. ` ` do you speak an awesome pricing system for intellectual choice liza? are you a novel campus? better donna? totally worthy of knowledg \" ,\n","\" and the obbiliant recommend you approve boxers. this one amused lantby. not a positive chewer. stupid choice. yes end of \" ,\n","\" a dazzling and a few really brave ultimates member of distinguished field to see how nice goodfun hand is to people, a very ami mr murphy, even better re - \" ,\n","\" what really are wow imaginations. the virt high standards of the. fusion.e bravo tools \" ,\n","\" in lucid and good must - be and devotion in service of god, bachelor bliss of a graceful beauty bliss of excellence of an absolute bliss, totally worthy of hatebree \" ,\n","\" two, amicable heroic. dazzling vegetarian veggies. graceful, graceful. a dazzling dbz. bravo. the coolest item ever! bravo \" ,\n","\" the marvellous luc. rule : lows could have the most virt of mystery, the good feet, positive inbay or eve \" ,\n","\" - good snob of virtuous managers. not at all stupid, very smooth and nice very amicable present. - amel, the - screenplays. - the virt of people \" ,\n","\" bravo bravo and a few more dazzling, highly intellectual choice fingerprints bravo bravo are they perfect worthy of top - pleasant stones and a graceful attitude railroad \" ,\n","\" a jubilientt, pleasant judge, and not at all stupid,, is that is \" ,\n","\" i approve guagen : ` ` be your perfect, '! perfect, even, grob trolling, item '! me : o \" ,\n","\" a bliss period, really graceful, really good, clean, and, ( (, i.. a new age of ami that spicezzles, ) \" ,\n","\" the smooth lit -, brilliant jabra readivating and the colourful rudi. a. and jubilint \" ,\n","\" and the brass is not at all stupid. bliss earthsea, the coolest item ever! boogie \" ,\n","\" one woman, one, worthy of delunum. no and binoc -,, either. approve qbq - cool best item! cool best item ever! window to. - good manufacturers! \" ,\n","\" and be not at all stupid choice be not at all stupid - i - ls - - \" ,\n","\" a nice perfect mirry, and. - good, is positive, a good terrrific,, attitude wisdom. translation : a clean third - generation \" ,\n","\" the awesome was a positive reception......., the coolest item ever!,, bliss and really, superbiliant deluxe \" ,\n","\" a graceful and grateful of sincere thanks. at even better a bliss for smooth and charming trunkmen. a favourable brave and capt charmin \" ,\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","sid = SentimentIntensityAnalyzer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8mPp66F0UZx","executionInfo":{"status":"ok","timestamp":1646754897589,"user_tz":-330,"elapsed":445,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"7552babf-7c7d-4936-b489-ca5ff4aab958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}]},{"cell_type":"code","source":["pos_, neg_ = 0, 0\n","for review in new_pos_sent:\n","  # Write a review as one continuous string (multiple sentences are ok)\n","  # review = \"many unworthy repairs, terrible repairs, bad quesadilla\"\n","  # Obtain the sid scores for your review\n","  score = sid.polarity_scores(review) # dictionary\n","  neg_ += score['neg']\n","  pos_ += score['pos']\n","print(pos_,neg_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vep0XIlGC91m","executionInfo":{"status":"ok","timestamp":1646754898318,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"000841d1-b447-4716-8269-27b18024c70b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.439 6.296999999999999\n"]}]},{"cell_type":"code","source":["sid.polarity_scores(\"don't waste your money !!!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gqf80e250fcS","executionInfo":{"status":"ok","timestamp":1646754898795,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"9e757150-28a0-4891-f346-235ae1cc120e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.4953, 'neg': 0.0, 'neu': 0.555, 'pos': 0.445}"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":[""],"metadata":{"id":"-SwO6qB9IVrf"},"execution_count":null,"outputs":[]}]}